ML Day_100 馬拉松

資料清理數據前處裡
Day_001  資料介紹與評估資料
Day_002  讀取資料EDA: Data summary
Day_003  3-1如何新建一個 dataframe?3-2 如何讀取其他資料? (非 csv 的資料)
Day_004  EDA: 欄位的資料類型介紹及處理
Day_005  EDA資料分佈
Day_006  EDA: Outlier 及處理
Day_007  常用的數值取代：中位數與分位數連續數值標準化
Day_008  DataFrame operationData frame merge/常用的 DataFrame 操作
Day_009  程式實作 EDA: correlation/相關係數簡介
Day_010  EDA from Correlation
Day_011  EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)
Day_012  EDA: 把連續型變數離散化
Day_013  程式實作 把連續型變數離散化
Day_014  Subplots
Day_015  Heatmap & Grid-plot
Day_016  模型初體驗 Logistic Regression

資料科學特徵工程技術
Day_017  特徵工程簡介
Day_018  特徵類型
Day_019  數值型特徵-補缺失值與標準化
Day_020  數值型特徵 - 去除離群值
Day_021  數值型特徵 - 去除偏態
Day_022  類別型特徵 - 基礎處理
Day_023  類別型特徵 - 均值編碼
Day_024  類別型特徵 - 其他進階處理
Day_025  時間型特徵
Day_026  特徵組合 - 數值與數值組合
Day_027  特徵組合 - 類別與數值組合
Day_028  特徵選擇
Day_029  特徵評估
Day_030  分類型特徵優化 - 葉編碼

機器學習基礎模型建立
Day_031  機器學習概論
Day_032  機器學習-流程與步驟
Day_033  機器如何學習?
Day_034  訓練/測試集切分的概念
Day_035  regression vs. classification
Day_036  評估指標選定/evaluation metrics
Day_037  regression model 介紹 - 線性迴歸/羅吉斯回歸
Day_038  regression model 程式碼撰寫
Day_039  regression model 介紹 - LASSO 回歸/ Ridge 回歸
Day_040  regression model 程式碼撰寫
Day_041  tree based model - 決策樹 (Decision Tree) 模型介紹
Day_042  tree based model - 決策樹程式碼撰寫
Day_043  tree based model - 隨機森林 (Random Forest) 介紹
Day_044  tree based model - 隨機森林程式碼撰寫
Day_045  tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹
Day_046  tree based model - 梯度提升機程式碼撰寫

機器學習調整參數
Day_047  超參數調整與優化
Day_048  Kaggle 競賽平台介紹
Day_049  集成方法 : 混合泛化(Blending)
Day_050  集成方法 : 堆疊泛化(Stacking)

Day_051-053  Kaggle期中考

非監督式機器學習
Day_054  clustering 1 非監督式機器學習簡介
Day_055  clustering 2 聚類算法
Day_056  K-mean 觀察 : 使用輪廓分析
Day_057  clustering 3 階層分群算法
Day_058  階層分群法 觀察 : 使用 2D 樣版資料集
Day_059  dimension reduction 1 降維方法-主成份分析
Day_060  PCA 觀察 : 使用手寫辨識資料集
Day_061  dimension reduction 2 降維方法-T-SNE
Day_062  t-sne 觀察 : 分群與流形還原

深度學習理論實作
Day_063  神經網路介紹
Day_064  深度學習體驗 : 模型調整與學習曲線
Day_065  深度學習體驗 : 啟動函數與正規化

初探深度學習使用keras
Day_066  Keras 安裝與介紹
Day_067  Keras Dataset
Day_068  Keras Sequential API
Day_069  Keras Module API
Day_070  Multi-layer Perception多層感知
Day_071  損失函數
Day_072  啟動函數
Day_073  梯度下降Gradient Descent
Day_074  Gradient Descent 數學原理
Day_075  BackPropagation
Day_076  優化器optimizers
Day_077  訓練神經網路的細節與技巧 - Validation and overfit
Day_078  訓練神經網路前的注意事項
Day_079  訓練神經網路的細節與技巧 - Learning rate effect
Day_080  [練習 Day] 優化器與學習率的組合與比較
Day_081  訓練神經網路的細節與技巧 - Regularization
Day_082  訓練神經網路的細節與技巧 - Dropout
Day_083  訓練神經網路的細節與技巧 - Batch normalization
Day_084  [練習 Day] 正規化/機移除/批次標準化的 組合與比較
Day_085  訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop
Day_086  訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model
Day_087  訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate
Day_088  訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數
Day_089  訓練神經網路的細節與技巧 - 撰寫自己的 Loss function
Day_090  使用傳統電腦視覺與機器學習進行影像辨識
Day_091  [練習 Day] 使用傳統電腦視覺與機器學習進行影像辨識

深度學習應用卷積神經網路
Day_092  卷積神經網路 (Convolution Neural Network, CNN) 簡介
Day_093  卷積神經網路架構細節
Day_094  卷積神經網路 - 卷積(Convolution)層與參數調整
Day_095  卷積神經網路 - 池化(Pooling)層與參數調整
Day_096  Keras 中的 CNN layers
Day_097  使用 CNN 完成 CIFAR-10 資料集
Day_098  訓練卷積神經網路的細節與技巧 - 處理大量數據
Day_099  訓練卷積神經網路的細節與技巧 - 處理小量數據
Day_100  訓練卷積神經網路的細節與技巧 - 轉移學習 (Transfer learning)

Day_101-103  Kaggle期末考

Bonus 進階補充
Day_104  互動式網頁神經網路視覺化
Day_105  CNN卷積網路回顧
Day_106  常見影像資料集介紹 (Cifar-10, ImageNet, COCO)
Day_107  電腦視覺應用介紹 - 影像分類, 影像分割, 物件偵測
